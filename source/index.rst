.. Chern documentation master file, created by
   sphinx-quickstart on Sat Jul 15 19:59:40 2017.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.


Chern documentation
====================
In the data analysis, the usual case is that we should process the data using different program one by one.
However, with the progress of the experiment, we need to contienous update the models and the parameters.
The update usually makes our program and our data more dirty and more messeous.
This project is intended to provide a tool to manage the projects and make our analysis and make a more comfortable life.

The following is added after the presentation of Sebastian Neubert at LHCb Analysis and Software Week, on July 18th, 2017. The purpose is to explain the idea and the design of this project and invite more human power to the project.

As for analysis preservation, I recommend to force the users to use git and write readme of their analysis.
The best way to force them to do so is to rewrite the shell. And make every shell command recorded by git.
However, it is impossible to create a new shell use for HEP. I recommend to use IPython as the shell and modify 
the functions of `mkdir`, `mv`, `rm`, `cp` etc.

Design philosophy of Chern
---------

.. figure:: fig/liuchengtu1.png

   Workflow of a demo analysis (made by Shunan Zhang)

Abstract workflow:
~~~~~~~~
The concept of workflow is similar with that of the most pipeline tools. 
An typical analysis is modeled as a workflow.
The data, task and algorithm can be modeled as some virtual object called VObject.
The VObjects are linked by their relationships.
The basic idea of Chern is to manage this flow.
In the figure above, the "raw data" is processed by a VTask called "task selection" and generate VData called "data after selection". The VTask "task selection" use an VAlgorithm "algorithm selection". The VData "data after selection" is further processed by an VTask called "task fit", which uses "algorithm fit" and generates data file called "result after fit". The specific mean of VData, VTask and VAlgorithm will be explained as following.

+ VData: The concept of data seems straight forward. However, here data include also the plots and other information generated by a program. And they are not the real data but only the expect input and output of the programs. 
+ VAlgorithm:
+ VTask: 

The algorithm means the code and the compile flow. It seems that snakemake provide a good tool to manage the compile flow.

.. figure:: fig/fig2.png

   Demo analysis structure (mad by Shunan Zhang)

data
selection1_algorithm
selection2_algorithm
fit_algorithm
selection1_task
data_after_selection1
selection2_task
data_after_selection2
fit_task
fit_result

For the purpose of preservation, I recommend to force users to use git lab and write readme.
The best approach to f

Contents:

.. toctree::
   :maxdepth: 2

   start
   installation
   module
   DeveloperGuide
   schedule
